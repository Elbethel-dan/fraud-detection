{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ef3852",
   "metadata": {},
   "source": [
    "# Model Building & Training for Fraud and Credit Card Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b55d54",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ae5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774ef461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_loader import load_data\n",
    "from scripts.model import run_modeling_pipeline, select_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7691a69",
   "metadata": {},
   "source": [
    "Loading Fraud Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2061c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data (\"/Users/elbethelzewdie/Downloads/fraud-detection/fraud-detection/data/processed/fraud_preprocessed_train_smote.csv\")\n",
    "test_df = load_data(\"/Users/elbethelzewdie/Downloads/fraud-detection/fraud-detection/data/processed/fraud_preprocessed_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8064fa",
   "metadata": {},
   "source": [
    "Separating the target variable from Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c8eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "TARGET = \"class\"\n",
    "\n",
    "# Split features and target\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]\n",
    "\n",
    "X_test = test_df.drop(columns=[TARGET])\n",
    "y_test = test_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bab63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (168303, 42)\n",
      "Test shape: (25830, 42)\n",
      "\n",
      "Class distribution (train):\n",
      "class\n",
      "0.0    0.555558\n",
      "1.0    0.444442\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution (test):\n",
      "class\n",
      "0.0    0.904994\n",
      "1.0    0.095006\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check shapes and class distribution\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "print(\"\\nClass distribution (train):\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution (test):\")\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52c675c",
   "metadata": {},
   "source": [
    "Run modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99cad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run modeling pipeline\n",
    "results = run_modeling_pipeline(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa68b2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>AUC_PR_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.952732</td>\n",
       "      <td>0.989911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.662097</td>\n",
       "      <td>0.776104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   F1_mean  AUC_PR_mean\n",
       "1        Random Forest  0.952732     0.989911\n",
       "0  Logistic Regression  0.662097     0.776104"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df, best_model, justification = select_best_model(results)\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75295ad4",
   "metadata": {},
   "source": [
    "- The Random Forest model significantly outperforms the Logistic Regression model, achieving a high F1-score of 0.953 and an AUC-PR of 0.990. This suggests that the Random Forest classifier is far superior at identifying fraud cases, demonstrating excellent precision and recall, which is crucial for imbalanced fraud datasets.\n",
    "\n",
    "- The Logistic Regression model's lower performance (F1 $\\approx 0.662$, AUC-PR $\\approx 0.776$) indicates it struggles more with the complexity and imbalance typically present in fraud detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d17906",
   "metadata": {},
   "source": [
    "Choosing the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a863f108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: Random Forest\n",
      "Justification: Random Forest was selected based on the highest mean AUC-PR across stratified 5-fold cross-validation. Logistic Regression is retained as a strong baseline due to its interpretability and transparency.\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected model:\", best_model)\n",
    "print(\"Justification:\", justification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2e4a63",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3426ae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "Confusion Matrix:\n",
      "[[15294  8082]\n",
      " [  725  1729]]\n",
      "\n",
      "Random Forest\n",
      "Confusion Matrix:\n",
      "[[23242   134]\n",
      " [ 1098  1356]]\n"
     ]
    }
   ],
   "source": [
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics[\"test_metrics\"][\"Confusion_Matrix\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16db5d",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "- The Logistic Regression model successfully detects a relatively high number of fraudulent transactions (high TP) and has fewer missed fraud cases (lower FN). However, it produces a very large number of false positives. In a real-world fraud detection system, this would lead to many legitimate customers being incorrectly flagged, increasing operational costs and customer dissatisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2dce4",
   "metadata": {},
   "source": [
    "- The Random Forest model significantly reduces false positives, making it more conservative when flagging fraud. This is desirable in operational settings where unnecessary fraud alerts are costly. However, the model misses more fraudulent transactions compared to Logistic Regression, resulting in a higher false negative rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f949b164",
   "metadata": {},
   "source": [
    "Loading Credit Card Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71385359",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data (\"/Users/elbethelzewdie/Downloads/fraud-detection/fraud-detection/data/processed/creditcard_preprocessed_train_smote.csv\")\n",
    "test_df = load_data(\"/Users/elbethelzewdie/Downloads/fraud-detection/fraud-detection/data/processed/creditcard_preprocessed_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb0541",
   "metadata": {},
   "source": [
    "Separating the target variable from Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5abfbf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'class'\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]\n",
    "\n",
    "X_test = test_df.drop(columns=[TARGET])\n",
    "y_test = test_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "918a0ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (407883, 30)\n",
      "Test shape: (56746, 30)\n",
      "\n",
      "Class distribution (train):\n",
      "class\n",
      "0    0.555556\n",
      "1    0.444444\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution (test):\n",
      "class\n",
      "0    0.998326\n",
      "1    0.001674\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check shapes and class distribution\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "print(\"\\nClass distribution (train):\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution (test):\")\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46c2c8",
   "metadata": {},
   "source": [
    "Run modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01433213",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_modeling_pipeline(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a296fc",
   "metadata": {},
   "source": [
    "Choosing the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ead5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>AUC_PR_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.944133</td>\n",
       "      <td>0.990671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   F1_mean  AUC_PR_mean\n",
       "1        Random Forest  0.999879     0.999997\n",
       "0  Logistic Regression  0.944133     0.990671"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df, best_model, justification = select_best_model(results)\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac6ce2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: Random Forest\n",
      "Justification: Random Forest was selected based on the highest mean AUC-PR across stratified 5-fold cross-validation. Logistic Regression is retained as a strong baseline due to its interpretability and transparency.\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected model:\", best_model)\n",
    "print(\"Justification:\", justification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaba147",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1299a0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "Confusion Matrix:\n",
      "[[55192  1459]\n",
      " [   12    83]]\n",
      "Classification Report:\n",
      "\n",
      "Random Forest\n",
      "Confusion Matrix:\n",
      "[[56645     6]\n",
      " [   24    71]]\n",
      "Classification Report:\n"
     ]
    }
   ],
   "source": [
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics[\"test_metrics\"][\"Confusion_Matrix\"])\n",
    "    print(\"Classification Report:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f532b",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "- Logistic Regression correctly identifies most fraud cases (TP=83) but misclassifies a small number of non-fraud transactions as fraud (FP=1,459). False negatives are very low (12), which is important because catching fraud is more critical than avoiding false alarms. Overall, the model performs reasonably well, but there is room to improve precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a0dbe",
   "metadata": {},
   "source": [
    "- Random Forest drastically reduces false positives (only 6), meaning very few legitimate transactions are flagged as fraud. However, it misses slightly more fraud cases than Logistic Regression (FN=24 vs FN=12), which can be critical depending on the business objective. This trade-off indicates that Random Forest is more conservative in flagging fraud, prioritizing precision over recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
